{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3-mle-optimization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNPbSlhoRazq3uMscgHjQAn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DepartmentOfStatisticsPUE/bi-2021/blob/main/materials/3_mle_optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7QawdiVUACk"
      },
      "source": [
        "# Metoda największej wiarygodności\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6KiRA1uUD9H"
      },
      "source": [
        "\n",
        "## Teoria\n",
        "\n",
        "If $f_{i}\\left(k_{i} ; \\mathbf{\\theta}\\right)$ is the PDF of a random-variable  where  $\\mathbf{\\theta}$ is a vector of parameters (e.g. $\\lambda$ in Poisson distribution), then for a collection of $N$ independent samples from this distribution, the joint distribution the random vector  $k_i$ is\n",
        "\n",
        "\\begin{equation}\n",
        "        f(\\mathbf{k} ; \\mathbf{\\theta})=\\prod_{i=1}^{N} f_{i}\\left(k_{i} ; \\mathbf{\\theta}\\right)\n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "The maximum likelihood estimate of the parameters  $\\mathbf{\\theta}$ are the parameters which maximize this function with $\\mathbf{x}$ fixed and given by the data:\n",
        "\n",
        "\\begin{equation}\n",
        "    \\hat{\\mathbf{\\theta}} =\\arg \\max _{\\mathbf{\\theta}} f(\\mathbf{k} ; \\mathbf{\\theta}) =\\arg \\min _{\\theta} l_{\\mathbf{k}}(\\mathbf{\\theta}),\n",
        "\\end{equation}\n",
        "\n",
        "where \n",
        "\n",
        "\n",
        "\\begin{equation}\n",
        "    l_{\\mathrm{k}}(\\mathbf{\\theta}) =-\\sum_{i=1}^{N} \\log f\\left(k_{i} ; \\mathbf{\\theta}\\right) =-N \\log f\\left(k_{i} ; \\mathbf{\\theta}\\right) \n",
        "\\end{equation}\n",
        "\n",
        "## Maximum likelihood -- przykład dla rozkładu Poissona\n",
        "\n",
        "\n",
        "Likelihood function for Poisson distribution is\n",
        "\n",
        "\\begin{equation}\n",
        "        L\\left(\\lambda ; x_{1}, \\ldots, x_{n}\\right)=\\prod_{j=1}^{n} \\exp (-\\lambda) \\frac{1}{x_{j} !} \\lambda^{x_{j}}\n",
        "\\end{equation}\n",
        "\n",
        "The log-likelihood function is\n",
        "\n",
        "\n",
        "\\begin{equation}\n",
        "        l\\left(\\lambda ; x_{1}, \\ldots, x_{n}\\right)=-n \\lambda-\\sum_{j=1}^{n} \\ln \\left(x_{j} !\\right)+\\ln (\\lambda) \\sum_{j=1}^{n} x_{j}\n",
        "\\end{equation}\n",
        "\n",
        "The maximum likelihood estimator of $\\lambda$\n",
        "\n",
        "\\begin{equation}\n",
        "        \\hat{\\lambda}=\\frac{1}{n} \\sum_{j=1}^{n} x_{j}\n",
        "\\end{equation}\n",
        "\n",
        "## Maximum likelihood -- practice\n",
        "\n",
        "+ Depending on the distribution it is possible to derive closed form for the parameters $\\mathbf{\\theta}$.\n",
        "+ In other cases, numerical methods that require gradient (first derivatives) and hessian (second derivatives) are used, for example Newton-Raphson method:\n",
        "+ Statistical packages also implement derivative-free optimization methods that do not require to calculate gradient and hessian.\n",
        "\n",
        "\n",
        "## Newton's method -- single parameter function\n",
        "\n",
        "Let $f$: $\\mathbb{R}^1 \\to \\mathbb{R}^1 $ be a differentiable function. We seek a solution of $f(x)=0$, starting from an initial estimate $x_0=x_1$. \n",
        "    \n",
        "At the $n$'s step, given $x_n$,  compute the next approximation $x_{n+1}$ by\n",
        "    \n",
        "\\begin{equation}\n",
        "        x_{n+1} = x_{n} - \\frac{f(x_n)}{f'(x_n)}\n",
        "\\end{equation} \n",
        "    \n",
        "and repeat until converge (i.e. $|x_{n+1}-x_n| < \\epsilon$).\n",
        "    \n",
        "For step by step examples see: http://amsi.org.au/ESA_Senior_Years/SeniorTopic3/3j/3j_2content_2.html.\n",
        "\n",
        "\n",
        "## Newton-Rapshon algorithm -- multivariate case\n",
        "\n",
        " Newton's method for optimization consists of applying Newton's method for solving systems of equations, where the equations are the first order conditions, saying that the gradient should equal the zero vector.\n",
        "    \n",
        "\\begin{equation}\n",
        "        \\nabla \\mathbf{f}(\\mathbf{x}) = \\mathbf{0}\n",
        "\\end{equation}\n",
        "    \n",
        "A second order Taylor expansion of the left-hand side leads to the iterative scheme\n",
        "\n",
        "\\begin{equation}\n",
        "    \\mathbf{x}_{n+1} = \\mathbf{x}_{n} - \\mathbf{H}(\\mathbf{x}_{n})^{-1}\\nabla \\mathbf{f}(\\mathbf{x}_{n}),\n",
        "\\end{equation}\n",
        "\n",
        "where $\\nabla \\mathbf{f}(\\mathbf{x}_{n})$ is a gradient and $\\mathbf{H}(\\mathbf{x}_{n})$ is a hessian of $\\mathbf{f}(\\mathbf{x}_{n})$ (second order derivatives). \n",
        "\n",
        "## Optimization procedures\n",
        "\n",
        "There are plenty of different optimisation procedures that may be used for estimating parameters:\n",
        "\n",
        " + Gradient free\n",
        "\n",
        "    + Nelder-Mead\n",
        "    + Simulated Annealing\n",
        "    + Particle Swarm\n",
        "\n",
        "+ Gradient required\n",
        "    + Conjugate Gradient Descent\n",
        "    + Gradient Descent\n",
        "    + (L-)BFGS\n",
        "\n",
        "+ Hessian required\n",
        "    + Newton's Method\n",
        "    + Newton's Method With a Trust Region\n",
        "\n",
        "For more, see **Optim.jl** documentation https://julianlsolvers.github.io/Optim.jl or **scipy.optimize** https://docs.scipy.org/doc/scipy/reference/tutorial/optimize.html."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvg8XDyVcLNc"
      },
      "source": [
        "# Przykład #1 \n",
        " \n",
        "## Zadanie\n",
        "\n",
        "Assume that $X$ follows zero-truncated Poisson distribution given by\n",
        "\n",
        "$$\n",
        "P(X=x, X>0; \\lambda) = \\frac{f(x; \\lambda)}{1 - f(0;\\lambda)} = \\frac{\\lambda^x e^{-\\lambda}}{x!(1-e^{-\\lambda})} =  \\frac{\\lambda^x}{(e^\\lambda-1)x!},\n",
        "$$\n",
        "\n",
        "complete the following task:\n",
        "\n",
        "+ estimate $\\lambda$ based on the maximum likelihood estimation method.\n",
        "+ Note that, obtaining $\\lambda$ requires deriving log-likelihood function (also gradient with respect to $\\lambda$) and applying optimization procedure (e.g. \\texttt{optim} function).\n",
        "\n",
        "\n",
        "## Rozwiązanie\n",
        "\n",
        "We start with likelihood function\n",
        "\n",
        "$$\n",
        "L = \\prod_i \\frac{\\lambda^x_i}{(e^\\lambda-1)x_i!},\n",
        "$$\n",
        "\n",
        "then we compute log-likelihood\n",
        "\n",
        "$$\n",
        "    \\log L = \\log\n",
        "    \\left(\n",
        "    \\prod_i \\frac{\\lambda^x_i}{(e^\\lambda-1)x_i!}\n",
        "    \\right) = \n",
        "    \\sum_i \\log \n",
        "    \\left( \n",
        "    \\frac{\\lambda^x_i}{(e^\\lambda-1)x_i!}\n",
        "    \\right)\n",
        "$$ \n",
        "\n",
        "after simplification we get\n",
        "\n",
        "$$\n",
        "\\log L = \\sum_i x_i \\log \\lambda - \\sum_i \\log(e^\\lambda-1) - \\sum_i \\log(x_i!) \n",
        "$$ \n",
        "\n",
        "In order to get estimate of $\\lambda$ we need to calculate derivatives with respect to this parameter. Thus, gradient is given by \n",
        "\n",
        "$$\n",
        "\\frac{\\partial \\log L}{\\partial \\lambda} = \\frac{\\sum_i x_i}{\\lambda} - \\frac{n e^\\lambda}{e^\\lambda - 1} = \\frac{\\sum_i x_i}{\\lambda} - n \\frac{e^\\lambda}{e^\\lambda - 1}. \n",
        "$$\n",
        "\n",
        "We can also calculate second derivative (hessian)\n",
        "\n",
        "$$\n",
        "\\frac{\\partial^2 \\log L}{\\partial \\lambda^2} =  - \\frac{\\sum_i x_i}{\\lambda^2} + n \\frac{e^\\lambda}{(e^\\lambda-1)^2}.\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vj0bIYVBUE0r"
      },
      "source": [
        "# Implementacja w R\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaEzTfUJTyh7",
        "outputId": "330f8137-24ed-4a82-f9d1-306c5d0b4608"
      },
      "source": [
        "install.packages(c(\"rootSolve\", \"maxLik\", \"extraDistr\", \"numDeriv\", \"rbenchmark\"))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing packages into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘zoo’, ‘miscTools’, ‘sandwich’\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kswvi5MY4E7"
      },
      "source": [
        "library(maxLik) ## optymaizacja (maksymalizacja)\n",
        "library(rootSolve) ## rozwiązywanie (nie)liniowych układów równań postaci f(x) = 0\n",
        "library(extraDistr) ## ucięty rozkład poissona\n",
        "library(numDeriv) ## numeryczne wyznaczanie gradienty\n",
        "library(rbenchmark) ## benchmarki funkcji R "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ys_n0TAsvV9l"
      },
      "source": [
        "$$\n",
        "\\log L = \\sum_i x_i \\log \\lambda - \\sum_i \\log(e^\\lambda-1)\n",
        "$$ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kWMQ9E6cygP"
      },
      "source": [
        "ll <- function(par, x) {\n",
        "  m <- sum(x)*log(par)-length(x)*log(exp(par)-1)\n",
        "  m\n",
        "}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xGMCGs_vaJ_"
      },
      "source": [
        "$$\n",
        "\\frac{\\partial \\log L}{\\partial \\lambda} = \\frac{\\sum_i x_i}{\\lambda} - n \\frac{e^\\lambda}{e^\\lambda - 1}. \n",
        "$$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEPBb2jXcz-2"
      },
      "source": [
        "grad <- function(par, x)  {\n",
        "  g <- sum(x) / par - length(x)*exp(par)/(exp(par)-1)\n",
        "  g\n",
        "}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "delWBQnLvdzb"
      },
      "source": [
        "$$\n",
        "\\frac{\\partial^2 \\log L}{\\partial \\lambda^2} =  - \\frac{\\sum_i x_i}{\\lambda^2} + n \\frac{e^\\lambda}{(e^\\lambda-1)^2}.\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7U2dV8Wc2Tb"
      },
      "source": [
        "hess <- function(par, x) {\n",
        "  h <- -sum(x)/par^2 + length(x)*exp(par)/(exp(par)-1)^2 \n",
        "  h\n",
        "}"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXrK6a6mvfLq"
      },
      "source": [
        "Generujemy dane z uciętego rozkładu Poissona z $\\lambda=2.5$. Przez argument `a` określamy punkt ucięcia. \n",
        "\n",
        "Te dane wykorzystamy do naszego badania zakładając, że nie znamy parametru $\\lambda$ i musimy go oszacować.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnyE2z6mc3s9"
      },
      "source": [
        "set.seed(123)\n",
        "x <- rtpois(10000, lambda = 2.5, a = 0)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZe7-sNgvw2M"
      },
      "source": [
        "Wykorzystujemy funkcję `maxLik` z pakietu o takiej samej nazwie. W argumencie `method=\"NR\"` wskazujemy, że wybieramy metodę Newtona-Raphsona. **UWAGA** ta funkcja dokonuje **MAKSYMALIZACJI**, w przeciwieństwie do innych funkcji (np. `optim` czy `scipy.optimize`), które dokonują minimalizacji. \n",
        "\n",
        "W poniższym kodzie wykorzystujemy tylko funkcję wiarygodności (`ll`), nie podajemy gradientu ani hessianu."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "Faki4ccNc5Xf",
        "outputId": "03b3caee-c869-4366-f73b-bc068dfb1223"
      },
      "source": [
        "res <- maxLik(logLik = ll, start = 1, x = x, method = \"NR\")\n",
        "summary(res)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "--------------------------------------------\n",
              "Maximum Likelihood estimation\n",
              "Newton-Raphson maximisation, 6 iterations\n",
              "Return code 2: successive function values within tolerance limit (tol)\n",
              "Log-Likelihood: 637.5431 \n",
              "1  free parameters\n",
              "Estimates:\n",
              "     Estimate Std. error t value Pr(> t)    \n",
              "[1,]  2.47732    0.01714   144.6  <2e-16 ***\n",
              "---\n",
              "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
              "--------------------------------------------"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMI0eEpOwWV4"
      },
      "source": [
        "W tym podejściu podajemy zarówno gradient `grad` jak i hessian `hess`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "BT7BeCUjc7uu",
        "outputId": "b460b917-7dd6-4c1a-f818-be1009da3b5f"
      },
      "source": [
        "res2 <- maxLik(logLik = ll,  grad = grad, hess = hess, start = 1, x = x, method = \"NR\")\n",
        "summary(res2)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "--------------------------------------------\n",
              "Maximum Likelihood estimation\n",
              "Newton-Raphson maximisation, 6 iterations\n",
              "Return code 1: gradient close to zero (gradtol)\n",
              "Log-Likelihood: 637.5431 \n",
              "1  free parameters\n",
              "Estimates:\n",
              "     Estimate Std. error t value Pr(> t)    \n",
              "[1,]  2.47732    0.01713   144.6  <2e-16 ***\n",
              "---\n",
              "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
              "--------------------------------------------"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZICM0UNwmnp"
      },
      "source": [
        "Otrzymujemy dokładnie takie same wyniki. Dlaczego? Bo metoda `NR` w pakiecie `maxLik` wykorzystuje algorytm numerycznego przybliżenia gradientu i hessianu, które zwłaszcza w przypadku małych wymiarów (tu mamy jeden parametr) dają takie samw wyniki. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12KLKJ2TgdMU"
      },
      "source": [
        "## Przykład 2\n",
        "\n",
        "Assume that $X$ follows Poisson distribution given by \n",
        "\n",
        "$$\n",
        "P(X=x, \\lambda_i) = \\frac{\\lambda^x e^{-\\lambda}}{x!},\n",
        "$$\n",
        "\n",
        "where $\\lambda_i = \\theta_0 + \\theta_1 \\times z_i$, $\\theta_0=1$, $\\theta_1=1.5$, and $z_i \\sim \\text{Bern}(0.7)$ and number of observations is equal to $n=10,000$.\n",
        "\n",
        "Tasks:\n",
        "\n",
        "+ generate $z_i$,\n",
        "+ generate $\\lambda_i$ according to $\\theta_0 + \\theta_1 \\times z_i$,\n",
        "+ generate $X \\sim Poisson(\\lambda_i)$\n",
        "+ derive log-likelihood, gradient and hessian,\n",
        "+ obtain MLE of $\\boldsymbol{\\theta} = (\\theta_0, \\theta_1)$ using Newton-Raphson method. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "id": "cIL9x3dGgrca",
        "outputId": "ae3e3306-06d2-4ef1-e182-264704a2e991"
      },
      "source": [
        "set.seed(123)\n",
        "n <- 10000\n",
        "z <- rbinom(n = n, prob = 0.7, size = 1)\n",
        "theta_true <- c(1, 1.5)\n",
        "lambda_true <- theta_true[1] + theta_true[2]*z\n",
        "X <- rpois(n = n, lambda = lambda_true)\n",
        "table(X)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "X\n",
              "   0    1    2    3    4    5    6    7    8    9   10   11 \n",
              "1675 2554 2361 1633 1060  414  208   67   23    3    1    1 "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2qodlfZna5E"
      },
      "source": [
        "Funkcja log-wiarygodności\n",
        "\n",
        "$$\n",
        "\\log L(\\theta_0, \\theta_1; X_i, z_i) = -\\lambda_i + x_i \\log(\\lambda_i) = -(\\theta_0 + \\theta_1z_i) + x_i \\log(\\theta_0 + \\theta_1z_i)\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EI7fxBrxhEmN"
      },
      "source": [
        "ll <- function(theta, z, X) {\n",
        "  \n",
        "  lam <- theta[1]+theta[2]*z\n",
        "  l <- X*log(lam) - lam\n",
        "  return(sum(l))\n",
        "}"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGLyP-YUz0cR"
      },
      "source": [
        "Gradient \n",
        "\n",
        "$$\n",
        "\\frac{\\partial \\log L}{\\partial \\mathbf{\\theta}} = \n",
        "\\begin{bmatrix}\n",
        "\\frac{\\partial \\log L}{\\partial \\theta_0} \\\\\n",
        "\\frac{\\partial \\log L}{\\partial \\theta_1}\n",
        "\\end{bmatrix} = \n",
        "\\begin{bmatrix}\n",
        "\\sum_i \\frac{x_i}{\\theta_0 + \\theta_1 z_i} - 1\\\\\n",
        "\\sum_i \\frac{x_i z_i}{\\theta_0 + \\theta_1 z_i} - z_i\n",
        "\\end{bmatrix}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfOj8Kph0PND"
      },
      "source": [
        "ll_grad <- function(theta, z, X) {\n",
        "  \n",
        "  lam <- theta[1]+theta[2]*z\n",
        "  l_g <- matrix(0, nrow = NROW(lam), ncol = 2)\n",
        "  l_g[,1] <- X/lam - 1\n",
        "  l_g[,2] <- X*z/lam - z\n",
        "  return(colSums(l_g))\n",
        "}"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tps_JQj21gq"
      },
      "source": [
        "Hessian\n",
        "\n",
        "$$\n",
        "\\frac{\\partial^2 \\log L}{\\partial \\mathbf{\\theta}^2} = \n",
        "\\begin{bmatrix}\n",
        "\\frac{\\partial^2 \\log L}{\\partial \\theta_0^2} & \\frac{\\partial^2 \\log L}{\\partial \\theta_0 \\partial\\theta_1} \\\\\n",
        "\\frac{\\partial^2 \\log L}{\\partial \\theta_0 \\partial\\theta_1} & \\frac{\\partial^2 \\log L}{\\partial \\theta_1^2} \\\\\n",
        "\\end{bmatrix} = \n",
        "\\begin{bmatrix}\n",
        "\\sum_i \\frac{-x_i}{(\\theta_0+ \\theta_1 z_i)^2} & \\sum_i \\frac{-x_i z_i}{(\\theta_0+ \\theta_1 z_i)^2} \\\\\n",
        "\\sum_i \\frac{-x_i z_i}{(\\theta_0+ \\theta_1 z_i)^2} & \\sum_i \\frac{-x_i z_i^2}{(\\theta_0+ \\theta_1 z_i)^2} \\\\\n",
        "\\end{bmatrix}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqfA4RjW43tf"
      },
      "source": [
        "ll_hess <- function(theta, z, X) {\n",
        "  \n",
        "  lam <- theta[1]+theta[2]*z\n",
        "  l_h <- matrix(0, nrow = 2, ncol = 2)\n",
        "  l_h[1,1] <- sum(-X / lam^2)\n",
        "  l_h[2,2] <- sum(-X * z^2 / lam^2)\n",
        "  l_h[1,2] <- l_h[2,1] <- sum(-X * z/ lam^2)\n",
        "  return(l_h)\n",
        "}"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "tsNZIb2NhVYA",
        "outputId": "d7217683-5150-448d-b76e-044ada401c1d"
      },
      "source": [
        "solution <- maxLik(logLik = ll, start = c(1,1), z = z, X = X, method = \"NR\")\n",
        "summary(solution)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "--------------------------------------------\n",
              "Maximum Likelihood estimation\n",
              "Newton-Raphson maximisation, 4 iterations\n",
              "Return code 8: successive function values within relative tolerance limit (reltol)\n",
              "Log-Likelihood: -4465.706 \n",
              "2  free parameters\n",
              "Estimates:\n",
              "     Estimate Std. error t value Pr(> t)    \n",
              "[1,]  0.96816    0.01810   53.48  <2e-16 ***\n",
              "[2,]  1.52560    0.02611   58.43  <2e-16 ***\n",
              "---\n",
              "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
              "--------------------------------------------"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "gNIBviEW1V4d",
        "outputId": "fb3f35b1-e79b-4b46-cc64-cee87c3aae69"
      },
      "source": [
        "solution <- maxLik(logLik = ll, grad =  ll_grad, hess = ll_hess, start = c(1,1), z = z, X = X, method = \"NR\")\n",
        "summary(solution)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "--------------------------------------------\n",
              "Maximum Likelihood estimation\n",
              "Newton-Raphson maximisation, 4 iterations\n",
              "Return code 1: gradient close to zero (gradtol)\n",
              "Log-Likelihood: -4465.706 \n",
              "2  free parameters\n",
              "Estimates:\n",
              "     Estimate Std. error t value Pr(> t)    \n",
              "[1,]  0.96816    0.01811   53.46  <2e-16 ***\n",
              "[2,]  1.52560    0.02611   58.43  <2e-16 ***\n",
              "---\n",
              "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
              "--------------------------------------------"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-wezmu_2ZUY"
      },
      "source": [
        "Porównajmy jakie wartości uzyskujemy z gradientu i hessianu wyznaczonego analitycznie, a jakie z wyznaczonego numerycznie."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "9luGz1R-2izW",
        "outputId": "dbac53b3-1b0f-4ea6-9922-8910fedc13b3"
      },
      "source": [
        "ll_grad(c(1,1), z=z, X=X)\n",
        "numDeriv::grad(ll, c(1,1), z=z, X= X)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 1646 1740"
            ],
            "text/latex": "\\begin{enumerate*}\n\\item 1646\n\\item 1740\n\\end{enumerate*}\n",
            "text/markdown": "1. 1646\n2. 1740\n\n\n",
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>1646</li><li>1740</li></ol>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 1646 1740"
            ],
            "text/latex": "\\begin{enumerate*}\n\\item 1645.99999992552\n\\item 1739.99999992291\n\\end{enumerate*}\n",
            "text/markdown": "1. 1645.99999992552\n2. 1739.99999992291\n\n\n",
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>1645.99999992552</li><li>1739.99999992291</li></ol>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "kB0I4MUv5Ojn",
        "outputId": "70974573-8026-4320-9b06-6f76742a1b74"
      },
      "source": [
        "ll_hess(c(1,1), z=z, X=X)\n",
        "numDeriv::hessian(ll, c(1,1), z=z, X=X)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     [,1]  [,2] \n",
              "[1,] -7252 -4394\n",
              "[2,] -4394 -4394"
            ],
            "text/latex": "A matrix: 2 × 2 of type dbl\n\\begin{tabular}{ll}\n\t -7252 & -4394\\\\\n\t -4394 & -4394\\\\\n\\end{tabular}\n",
            "text/markdown": "\nA matrix: 2 × 2 of type dbl\n\n| -7252 | -4394 |\n| -4394 | -4394 |\n\n",
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A matrix: 2 × 2 of type dbl</caption>\n",
              "<tbody>\n",
              "\t<tr><td>-7252</td><td>-4394</td></tr>\n",
              "\t<tr><td>-4394</td><td>-4394</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     [,1]  [,2] \n",
              "[1,] -7252 -4394\n",
              "[2,] -4394 -4394"
            ],
            "text/latex": "A matrix: 2 × 2 of type dbl\n\\begin{tabular}{ll}\n\t -7252 & -4394\\\\\n\t -4394 & -4394\\\\\n\\end{tabular}\n",
            "text/markdown": "\nA matrix: 2 × 2 of type dbl\n\n| -7252 | -4394 |\n| -4394 | -4394 |\n\n",
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A matrix: 2 × 2 of type dbl</caption>\n",
              "<tbody>\n",
              "\t<tr><td>-7252</td><td>-4394</td></tr>\n",
              "\t<tr><td>-4394</td><td>-4394</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enIfpCmq569C"
      },
      "source": [
        "Porównamy szybkość działania"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNCAZw006pND"
      },
      "source": [
        "## definiujemy sobie funkcje wcześniej\n",
        "ll_grad_numeric <- function(theta, z, X) {\n",
        "  numDeriv::grad(ll, theta, z=z, X=X)\n",
        "}\n",
        "\n",
        "ll_hess_numeric <- function(theta, z, X) {\n",
        "  numDeriv::hessian(ll, theta, z=z, X=X)\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "2-TAGXHd6Gv8",
        "outputId": "fea79982-59d5-4bb9-bc6f-f0773a58fea1"
      },
      "source": [
        "benchmark(maxlik_bez = maxLik(logLik = ll, start = c(1,1), z = z, X = X, method = \"NR\"), \n",
        "          maxlik_analytic_grad = maxLik(logLik = ll, grad =  ll_grad, hess = ll_hess, start = c(1,1), z = z, X = X, method = \"NR\"),\n",
        "          maxlik_analytic_grad_hess = maxLik(logLik = ll, grad =  ll_grad, start = c(1,1), z = z, X = X, method = \"NR\"),\n",
        "          maxlik_numerical = maxLik(logLik = ll, grad =  ll_grad_numeric, hess = ll_hess_numeric, start = c(1,1), z = z, X = X, method = \"NR\"))"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  test                      replications elapsed relative user.self sys.self\n",
              "2 maxlik_analytic_grad      100          0.950   1.000    0.930     0.019   \n",
              "3 maxlik_analytic_grad_hess 100          1.856   1.954    1.797     0.050   \n",
              "1 maxlik_bez                100          4.344   4.573    4.268     0.066   \n",
              "4 maxlik_numerical          100          8.960   9.432    8.827     0.122   \n",
              "  user.child sys.child\n",
              "2 0          0        \n",
              "3 0          0        \n",
              "1 0          0        \n",
              "4 0          0        "
            ],
            "text/latex": "A data.frame: 4 × 8\n\\begin{tabular}{r|llllllll}\n  & test & replications & elapsed & relative & user.self & sys.self & user.child & sys.child\\\\\n  & <chr> & <int> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n\\hline\n\t2 & maxlik\\_analytic\\_grad      & 100 & 0.950 & 1.000 & 0.930 & 0.019 & 0 & 0\\\\\n\t3 & maxlik\\_analytic\\_grad\\_hess & 100 & 1.856 & 1.954 & 1.797 & 0.050 & 0 & 0\\\\\n\t1 & maxlik\\_bez                & 100 & 4.344 & 4.573 & 4.268 & 0.066 & 0 & 0\\\\\n\t4 & maxlik\\_numerical          & 100 & 8.960 & 9.432 & 8.827 & 0.122 & 0 & 0\\\\\n\\end{tabular}\n",
            "text/markdown": "\nA data.frame: 4 × 8\n\n| <!--/--> | test &lt;chr&gt; | replications &lt;int&gt; | elapsed &lt;dbl&gt; | relative &lt;dbl&gt; | user.self &lt;dbl&gt; | sys.self &lt;dbl&gt; | user.child &lt;dbl&gt; | sys.child &lt;dbl&gt; |\n|---|---|---|---|---|---|---|---|---|\n| 2 | maxlik_analytic_grad      | 100 | 0.950 | 1.000 | 0.930 | 0.019 | 0 | 0 |\n| 3 | maxlik_analytic_grad_hess | 100 | 1.856 | 1.954 | 1.797 | 0.050 | 0 | 0 |\n| 1 | maxlik_bez                | 100 | 4.344 | 4.573 | 4.268 | 0.066 | 0 | 0 |\n| 4 | maxlik_numerical          | 100 | 8.960 | 9.432 | 8.827 | 0.122 | 0 | 0 |\n\n",
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.frame: 4 × 8</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>test</th><th scope=col>replications</th><th scope=col>elapsed</th><th scope=col>relative</th><th scope=col>user.self</th><th scope=col>sys.self</th><th scope=col>user.child</th><th scope=col>sys.child</th></tr>\n",
              "\t<tr><th></th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>2</th><td>maxlik_analytic_grad     </td><td>100</td><td>0.950</td><td>1.000</td><td>0.930</td><td>0.019</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>3</th><td>maxlik_analytic_grad_hess</td><td>100</td><td>1.856</td><td>1.954</td><td>1.797</td><td>0.050</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>1</th><td>maxlik_bez               </td><td>100</td><td>4.344</td><td>4.573</td><td>4.268</td><td>0.066</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>4</th><td>maxlik_numerical         </td><td>100</td><td>8.960</td><td>9.432</td><td>8.827</td><td>0.122</td><td>0</td><td>0</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWDxiYmm-fVT"
      },
      "source": [
        "W przypadku `maxlik_numerical` problemem jest wielokrotne definiowane gradientu z funkcją `numDeriv::grad`. Można to rozwiązać stosując pakiet `calculus`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVhR29sQEcIV"
      },
      "source": [
        "## Rozwiązanie układu równań\n",
        "\n",
        "Aby rozwiązać ten układ równań\n",
        "\n",
        "\\begin{equation}\n",
        "        \\nabla \\mathbf{f}(\\mathbf{x}) = \\mathbf{0},\n",
        "\\end{equation}\n",
        "\n",
        "możemy skorzystać z pakietu `rootSolve` i funkcji `multiroot`. W pythonie jest funkcja `scipy.optimize.root` (https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.root.html), a w Julii `NLsolve.jl` (https://github.com/JuliaNLSolvers/NLsolve.jl)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "id": "DLNAWIKcEmx4",
        "outputId": "15a3782c-9bd8-4260-e391-50a89357747f"
      },
      "source": [
        "solve_root <- rootSolve::multiroot(ll_grad, start = c(1,1), z = z, X = X)\n",
        "solve_root"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "$root\n",
              "[1] 0.9681572 1.5255999\n",
              "\n",
              "$f.root\n",
              "[1] 3.898787e-08 3.898748e-08\n",
              "\n",
              "$iter\n",
              "[1] 5\n",
              "\n",
              "$estim.precis\n",
              "[1] 3.898767e-08\n"
            ],
            "text/latex": "\\begin{description}\n\\item[\\$root] \\begin{enumerate*}\n\\item 0.968157181571816\n\\item 1.52559991262551\n\\end{enumerate*}\n\n\\item[\\$f.root] \\begin{enumerate*}\n\\item 3.89878679341038e-08\n\\item 3.89874817985358e-08\n\\end{enumerate*}\n\n\\item[\\$iter] 5\n\\item[\\$estim.precis] 3.89876748663198e-08\n\\end{description}\n",
            "text/markdown": "$root\n:   1. 0.968157181571816\n2. 1.52559991262551\n\n\n\n$f.root\n:   1. 3.89878679341038e-08\n2. 3.89874817985358e-08\n\n\n\n$iter\n:   5\n$estim.precis\n:   3.89876748663198e-08\n\n\n",
            "text/html": [
              "<dl>\n",
              "\t<dt>$root</dt>\n",
              "\t\t<dd><style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>0.968157181571816</li><li>1.52559991262551</li></ol>\n",
              "</dd>\n",
              "\t<dt>$f.root</dt>\n",
              "\t\t<dd><style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>3.89878679341038e-08</li><li>3.89874817985358e-08</li></ol>\n",
              "</dd>\n",
              "\t<dt>$iter</dt>\n",
              "\t\t<dd>5</dd>\n",
              "\t<dt>$estim.precis</dt>\n",
              "\t\t<dd>3.89876748663198e-08</dd>\n",
              "</dl>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113
        },
        "id": "h_IymX4AxPRB",
        "outputId": "7d2180c4-975e-4a6d-b3ec-ebd70c1509f8"
      },
      "source": [
        "solve_grad <- rootSolve::gradient(ll_grad, solve_root$root, z = z, X = X)\n",
        "solve_grad"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     [,1]      [,2]     \n",
              "[1,] -5875.349 -2826.258\n",
              "[2,] -2826.258 -2826.258"
            ],
            "text/latex": "A matrix: 2 × 2 of type dbl\n\\begin{tabular}{ll}\n\t -5875.349 & -2826.258\\\\\n\t -2826.258 & -2826.258\\\\\n\\end{tabular}\n",
            "text/markdown": "\nA matrix: 2 × 2 of type dbl\n\n| -5875.349 | -2826.258 |\n| -2826.258 | -2826.258 |\n\n",
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A matrix: 2 × 2 of type dbl</caption>\n",
              "<tbody>\n",
              "\t<tr><td>-5875.349</td><td>-2826.258</td></tr>\n",
              "\t<tr><td>-2826.258</td><td>-2826.258</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYdaNdsgyMQy"
      },
      "source": [
        "Jak otrzymać błędy standardowe? \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHrVGIt_yhHM"
      },
      "source": [
        "$$\n",
        "se(\\hat{\\mathbf{\\theta}}) = \\sqrt{diag(H(\\hat{\\mathbf{\\theta}})^{-1})}\n",
        "$$\n",
        "\n",
        "gdzie $H(\\hat{\\mathbf{\\theta}})$ to Hessian wyznaczony dla wektora $\\hat{\\mathbf{\\theta}}$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "gobZlZTbyJKN",
        "outputId": "3b256164-4741-4d12-bbd5-9ede461f72a4"
      },
      "source": [
        "sqrt(abs(diag(solve(solve_grad))))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 0.01810985 0.02611113"
            ],
            "text/latex": "\\begin{enumerate*}\n\\item 0.0181098461271584\n\\item 0.026111133756929\n\\end{enumerate*}\n",
            "text/markdown": "1. 0.0181098461271584\n2. 0.026111133756929\n\n\n",
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>0.0181098461271584</li><li>0.026111133756929</li></ol>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1x8NfimzQW5"
      },
      "source": [
        "Poniżej błędy standardowe wyznaczone na podstawie wyniku z obiektu `solution` utworzonego w wyniki `maxLik`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "aEN3s_oZzFE3",
        "outputId": "244a4edc-bad6-4f5d-c133-ca85f111bfb9"
      },
      "source": [
        "sqrt(diag(vcov(solution)))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 0.01810985 0.02611113"
            ],
            "text/latex": "\\begin{enumerate*}\n\\item 0.0181098460767258\n\\item 0.026111133856481\n\\end{enumerate*}\n",
            "text/markdown": "1. 0.0181098460767258\n2. 0.026111133856481\n\n\n",
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>0.0181098460767258</li><li>0.026111133856481</li></ol>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}