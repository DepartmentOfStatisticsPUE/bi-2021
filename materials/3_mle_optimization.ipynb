{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3-mle-optimization.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNWDXvgN8+P5WiYSAfeVg/g"
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7QawdiVUACk"
      },
      "source": [
        "# Metoda największej wiarygodności\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6KiRA1uUD9H"
      },
      "source": [
        "\n",
        "## Teoria\n",
        "\n",
        "If $f_{i}\\left(k_{i} ; \\mathbf{\\theta}\\right)$ is the PDF of a random-variable  where  $\\mathbf{\\theta}$ is a vector of parameters (e.g. $\\lambda$ in Poisson distribution), then for a collection of $N$ independent samples from this distribution, the joint distribution the random vector  $k_i$ is\n",
        "\n",
        "\\begin{equation}\n",
        "        f(\\mathbf{k} ; \\mathbf{\\theta})=\\prod_{i=1}^{N} f_{i}\\left(k_{i} ; \\mathbf{\\theta}\\right)\n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "The maximum likelihood estimate of the parameters  $\\mathbf{\\theta}$ are the parameters which maximize this function with $\\mathbf{x}$ fixed and given by the data:\n",
        "\n",
        "\\begin{equation}\n",
        "    \\hat{\\mathbf{\\theta}} =\\arg \\max _{\\mathbf{\\theta}} f(\\mathbf{k} ; \\mathbf{\\theta}) =\\arg \\min _{\\theta} l_{\\mathbf{k}}(\\mathbf{\\theta}),\n",
        "\\end{equation}\n",
        "\n",
        "where \n",
        "\n",
        "\n",
        "\\begin{equation}\n",
        "    l_{\\mathrm{k}}(\\mathbf{\\theta}) =-\\sum_{i=1}^{N} \\log f\\left(k_{i} ; \\mathbf{\\theta}\\right) =-N \\log f\\left(k_{i} ; \\mathbf{\\theta}\\right) \n",
        "\\end{equation}\n",
        "\n",
        "## Maximum likelihood -- przykład dla rozkładu Poissona\n",
        "\n",
        "\n",
        "Likelihood function for Poisson distribution is\n",
        "\n",
        "\\begin{equation}\n",
        "        L\\left(\\lambda ; x_{1}, \\ldots, x_{n}\\right)=\\prod_{j=1}^{n} \\exp (-\\lambda) \\frac{1}{x_{j} !} \\lambda^{x_{j}}\n",
        "\\end{equation}\n",
        "\n",
        "The log-likelihood function is\n",
        "\n",
        "\n",
        "\\begin{equation}\n",
        "        l\\left(\\lambda ; x_{1}, \\ldots, x_{n}\\right)=-n \\lambda-\\sum_{j=1}^{n} \\ln \\left(x_{j} !\\right)+\\ln (\\lambda) \\sum_{j=1}^{n} x_{j}\n",
        "\\end{equation}\n",
        "\n",
        "The maximum likelihood estimator of $\\lambda$\n",
        "\n",
        "\\begin{equation}\n",
        "        \\hat{\\lambda}=\\frac{1}{n} \\sum_{j=1}^{n} x_{j}\n",
        "\\end{equation}\n",
        "\n",
        "## Maximum likelihood -- practice\n",
        "\n",
        "+ Depending on the distribution it is possible to derive closed form for the parameters $\\mathbf{\\theta}$.\n",
        "+ In other cases, numerical methods that require gradient (first derivatives) and hessian (second derivatives) are used, for example Newton-Raphson method:\n",
        "+ Statistical packages also implement derivative-free optimization methods that do not require to calculate gradient and hessian.\n",
        "\n",
        "\n",
        "## Newton's method -- single parameter function\n",
        "\n",
        "Let $f$: $\\mathbb{R}^1 \\to \\mathbb{R}^1 $ be a differentiable function. We seek a solution of $f(x)=0$, starting from an initial estimate $x_0=x_1$. \n",
        "    \n",
        "At the $n$'s step, given $x_n$,  compute the next approximation $x_{n+1}$ by\n",
        "    \n",
        "\\begin{equation}\n",
        "        x_{n+1} = x_{n} - \\frac{f(x_n)}{f'(x_n)}\n",
        "\\end{equation} \n",
        "    \n",
        "and repeat until converge (i.e. $|x_{n+1}-x_n| < \\epsilon$).\n",
        "    \n",
        "For step by step examples see: http://amsi.org.au/ESA_Senior_Years/SeniorTopic3/3j/3j_2content_2.html.\n",
        "\n",
        "\n",
        "## Newton-Rapshon algorithm -- multivariate case\n",
        "\n",
        " Newton's method for optimization consists of applying Newton's method for solving systems of equations, where the equations are the first order conditions, saying that the gradient should equal the zero vector.\n",
        "    \n",
        "\\begin{equation}\n",
        "        \\nabla \\mathbf{f}(\\mathbf{x}) = \\mathbf{0}\n",
        "\\end{equation}\n",
        "    \n",
        "A second order Taylor expansion of the left-hand side leads to the iterative scheme\n",
        "\n",
        "\\begin{equation}\n",
        "    \\mathbf{x}_{n+1} = \\mathbf{x}_{n} - \\mathbf{H}(\\mathbf{x}_{n})^{-1}\\nabla \\mathbf{f}(\\mathbf{x}_{n}),\n",
        "\\end{equation}\n",
        "\n",
        "where $\\nabla \\mathbf{f}(\\mathbf{x}_{n})$ is a gradient and $\\mathbf{H}(\\mathbf{x}_{n})$ is a hessian of $\\mathbf{f}(\\mathbf{x}_{n})$ (second order derivatives). \n",
        "\n",
        "## Optimization procedures\n",
        "\n",
        "There are plenty of different optimisation procedures that may be used for estimating parameters:\n",
        "\n",
        " + Gradient free\n",
        "\n",
        "    + Nelder-Mead\n",
        "    + Simulated Annealing\n",
        "    + Particle Swarm\n",
        "\n",
        "+ Gradient required\n",
        "    + Conjugate Gradient Descent\n",
        "    + Gradient Descent\n",
        "    + (L-)BFGS\n",
        "\n",
        "+ Hessian required\n",
        "    + Newton's Method\n",
        "    + Newton's Method With a Trust Region\n",
        "\n",
        "For more, see **Optim.jl** documentation https://julianlsolvers.github.io/Optim.jl or **scipy.optimize** https://docs.scipy.org/doc/scipy/reference/tutorial/optimize.html."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vj0bIYVBUE0r"
      },
      "source": [
        "# Implementacja w R\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaEzTfUJTyh7"
      },
      "source": [
        "install.packages(c(\"rootSolve\", \"maxLik\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kswvi5MY4E7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}